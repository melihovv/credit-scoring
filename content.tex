\MelUnnumSec{Введение}

Нейронная сеть — это математическая модель, построенная по принципу организации
и функционирования биологических нейронных сетей — сетей нервных клеток живого
организма. С помощью нейронной сети можно решить такие
прикладные задачи, как: автоматизация процессов распознавания образов,
адаптивное управление, прогозирование, создание экспертных систем и многие
другие. Задача оценки кредитоспособности клиента банка, решаемая в данной
работе, как раз входит в круг вышеперечисленных задач.

\section{Постановка задачи}

Необходимо разработать программу, решающую задачу определения кредитоспособности
клиента банка с помощью библиотек для работы с нейронными сетями — AlgLib и
PyBrain. А также сравнить время обучения каждой из библиотек на одной и той же
обучающей выборке. Входными данными для нейронной сети являются следующие
признаки:

\begin{itemize}
    \item количество денег на текущем счете (вещественное число);
    \item срок кредита (вещественное число);
    \item срок кредита, разбитый по категориям (дискретное число);
    \item кредитная история (дискретное число);
    \item история кредита (дискретное число);
    \item сумма кредита (вещественное число);
    \item сумма кредита, разбитая по категориям (дискретное число);
    \item количество сбережений или ценных бумаг (дискретное число);
    \item время работы на текущем месте (дискретное число);
    \item рассрочка в \% от располагаемого дохода (дискретное число);
    \item пол, семейное положение (дискретное число);
    \item наличие поручителей (дискретное число);
    \item срок проживания в текущем месте жительства (дискретное число);
    \item самое ценное имущество (дискретное число);
    \item возраст (вещественное число);
    \item наличие других кредитов (дискретное число);
    \item тип жилья (дискретное число);
    \item количество предыдущих кредитов в этом банке (дискретное число);
    \item профессия (дискретное число);
    \item количество поручителей (дискретное число);
    \item наличие телефона (дискретное число);
    \item иностранец или нет (дискретное число).
\end{itemize}

\section{Теоретические сведения о нейорнных сетях}

Несмотря на большое разнообразие вариантов нейронных сетей, все они имеют общие
черты. Так, все они, так же, как и мозг человека, состоят из большого числа
связанных между собой однотипных элементов – нейронов, которые имитируют нейроны
головного мозга. На рисунке~\ref{img:neuron_scheme} показана схема нейрона.

\MelImg[.6\textwidth]{neuron_scheme}{Схема нейрона.}

Из рисунка видно, что искусственный нейрон, так же, как и живой, состоит из
синапсов, связывающих входы нейрона с ядром; ядра нейрона, которое осуществляет
обработку входных сигналов и аксона, который связывает нейрон с нейронами
следующего слоя \cite{korotkiy}. Каждый синапс имеет вес, который определяет,
насколько соответствующий вход нейрона влияет на его состояние. Состояние
нейрона определяется по формуле

\begin{equation}
S=\sum_{i=1}^{n}x_iw_i
\end{equation}

где
\begin{itemize}
    \item[$n$] — число входов нейрона,
    \item[$x_i$] — значение $i$-го нейрона,
    \item[$w_i$] — вес $i$-ого синапса.
\end{itemize}

Затем определяется значение аксона нейрона по формуле

\begin{equation}
    Y=f(S)
\end{equation}

где
\begin{itemize}
    \item[$f$] — некоторая функция, которая называется активационной.
\end{itemize}

Наиболее часто в качестве активационной функции используется так называемый
сигмоид, который имеет следующий вид:

\begin{equation}
    f(x)=\frac{1}{1+e^{-\alpha x}}
\end{equation}

Основное достоинство этой функции в том, что она дифференцируема на всей оси
абсцисс и имеет очень простую производную:

\begin{equation}
    f'(x)=\alpha f(x)(1-f(x))
\end{equation}

Возвращаясь к общим чертам, присущим всем нейронным сетям, отметим, во-вторых,
принцип параллельной обработки сигналов, который достигается путем объединения
большого числа нейронов в так называемые слои и соединения определенным образом
нейронов различных слоев, а также, в некоторых конфигурациях, и нейронов одного
слоя между собой, причем обработка взаимодействия всех нейронов ведется
послойно \cite{basegroup}.

Теоретически число слоев и число нейронов в каждом слое может быть произвольным,
однако фактически оно ограничено ресурсами компьютера или специализированной
микросхемы, на которых обычно реализуется нейронная сеть. Чем сложнее нейронная
сеть, тем масштабнее задачи, подвластные ей.

Выбор структуры нейронной сети осуществляется в соответствии с особенностями и
сложностью задачи. Для решения некоторых отдельных типов задач уже существуют
оптимальные, на сегодняшний день, конфигурации.

Процесс функционирования нейронной сети, то есть сущность действий, которые она
способна выполнять, зависит от величин синаптических связей, поэтому, задавшись
определенной структурой нейронной сети, отвечающей какой-либо задаче,
разработчик сети должен найти оптимальные значения всех переменных весовых
коэффициентов. Этот этап называется обучением нейронной сети, и от того,
насколько качественно он будет выполнен, зависит способность сети решать
поставленные перед ней проблемы во время эксплуатации. На этапе обучения кроме
параметра качества подбора весов важную роль играет время обучения. Как правило,
эти два параметра связаны обратной зависимостью и их приходится выбирать на
основе компромисса.

Обучение нейронной сети может вестись с учителем или без него. В первом случае
сети предъявляются значения как входных, так и желательных выходных сигналов, и
она по некоторому внутреннему алгоритму подстраивает веса своих синаптических
связей. Во втором случае выходы нейронной сети формируются самостоятельно, а
веса изменяются по алгоритму, учитывающему только входные и производные от них
сигналы. Существует великое множество различных алгоритмов обучения, которые,
однако делятся на два больших класса: детерминистские и стохастические. В первом
из них подстройка весов представляет собой жесткую последовательность действий,
во втором – она производится на основе действий, подчиняющихся некоторому
случайному процессу.

После того, как нейронная сеть обучена, ее можно применять для решения полезных
задач. Важнейшая особенность человеческого мозга состоит в том, что, однажды
обучившись определенному процессу, он может верно действовать и в тех ситуациях,
в которых он не бывал в процессе обучения. Например, мы можем читать почти любой
почерк, даже если видим его первый раз в жизни. Так же и нейронная сеть,
грамотным образом обученная, может с большой вероятностью правильно реагировать
на новые, не предъявленные ей ранее данные.

\section{Обзоро библиотек для работы с нейронными сетями}
\subsection{AlgLib}

AlgLib — это кросс-платформенная библиотека численного анализа, поддерживающая
несколько языков программирования (C++, C\#, Pascal, VBA) и несколько
операционных систем (Windows, Linux, Solaris) \cite{alglib_doc}. Эта библиотека
распространяется вместе с исходным кодом и может быть откомпилирована
практически на любой платформе с использованием практически любого компилятора.
С ее помощью можно легко решить широкий круг математических задач: произвести
быстрое Фурье-преобразование, решить систему дифференциальных уравнений, а также
решить задачу классификации или регрессии с помощью нейронных сетей.

\subsubsection{Работа с нейронными сетями}

Нейронная сеть в AlgLib представлена структурой MultiLayerPerceptron. Работа с
нейронными сетями осуществляется в такой последовательности:

\begin{enumerate}
    \item Выбор архитектуры и инициализация структуры при помощи соответствующей
        функции;
    \item Обучение нейронной сети при помощи одного из алгоритмов;
    \item Использование обученной сети.
\end{enumerate}

\subsubsection{Доступные архитектуры}

Пакет AlgLib позволяет создавать нейронные сети без скрытых слоев, с одним
скрытым слоем и с двумя скрытыми слоями. Соединения идут от входного слоя к
первому из скрытых (если он есть), затем ко второму, затем — к выходному.
«Короткие» соединения от входного слоя к выходному отсутствуют. Скрытые слои
имеют одну из стандартных сжимающих функций активации, однако для выходного слоя
нейронной сети возможно большее разнообразие. Выходной слой может быть линейным
(такие сети используются в задачах аппроксимации), может иметь сжимающую функцию
активации (в случае, если выходы сети ограничены определенным диапазоном). Также
доступны сети с ограниченной сверху (или снизу) функцией активации. В простейшем
случае (граница — ноль) эта функция стремится к $x$ при $x$ стремящемся к
$+\infty$, и экспоненциально стремится к нулю при x стремящемся к $-\infty$.

Особым случаем являются нейронные сети с линейным выходным слоем и
SOFTMAX-нормализацией выходов. Они используются для задач классификации, в
которых выходы сети должны быть неотрицательны и их сумма должна быть строго
равна единице, что позволяет использовать их, как вероятности отнесения входного
вектора к одному из классов (в предельном случае выходы обученной сети сходятся
к этим вероятностям). Число выходов такой сети всегда не менее двух
(ограничение, диктуемое элементарной логикой).

Такой набор архитектур, несмотря на свою минималистичность, достаточен для
решения большинства практических задач. Отсутствие излишних деталей позволяет
концентрироваться на задаче (классификация или аппроксимация), не уделяя
излишнего внимания несущественным деталям (например, выбор конкретной функции
активации нелинейного слоя обычно мало влияет на результат).

\subsubsection{Обучение нейронной сети}

Для обучения нейронной сети пользователь может использовать три алгоритма.
Первый из них — L-BFGS алгоритм (limited memory BFGS), квази-Ньютоновский метод
с трудоемкостью итерации, линейной по количеству весовых коэффициентов WCount и
размеру обучающего множества NPoints, и умеренными требованиями к дополнительной
памяти — O(WCount). Этот алгоритм идеально подходит для решения задач высокой
размерности, и неплохо ведет себя на задачах средней и малой размерности.
Критериями останова служат малая величина шага (менее передаваемого в
подпрограмму значения WStep) или превышение заданного числа итераций алгоритма
(параметра MaxIts).

Второй алгоритм — это модифицированный метод Левенберга-Марквардта, использующий
точный гессиан функции ошибки (НЕ линеаризованную аппроксимацию). На задачах
малой и средней размерности (до нескольких сотен весовых коэффициентов) этот
алгоритм часто оказывается быстрее L-BFGS, но его главное достоинство — даже не
скорость работы, а то, что он вообще не нуждается в указании критериев останова.
Этот метод всегда точно находит один из локальных минимумов функции (если только
задача не окажется настолько сложна, что он ошибочно решит на полпути, что уже
оказался в минимуме). Впрочем, есть и недостатки — трудоемкость итерации равна
$O(NPoints*WCount^2)$, затраты памяти — $O(WCount^2)$.

Третий алгоритм — метод раннего останова. Этот метод используется в составе
одного из алгоритмов конструирования ансамблей нейронных сетей.

Ещё одним важным вопросом является регуляризация. В пакете AlgLib использована
стандартная регуляризирующая добавка — сумма квадратов весовых коэффициентов
сети, умноженных на коэффициент Decay. Правильно выбранный коэффициент
регуляризации значительно улучшает как качество обученной нейросети, так и
скорость обучения.

\subsubsection{Кросс-валидация}

Кросс-валидация является хорошо известным методом оценки способности сложных
моделей к обобщению. В пакет AlgLib входят две подпрограммы, получающих
кросс-валидационную оценку способности сети к обобщению. Первая использует в
качестве базового алгоритма обучения метод Левенберга-Марквардта, вторая —
L-BFGS алгоритм.

\subsubsection{Формат обучающего множества}

Данные представляются в виде двухмерного массива, строки которого соответствуют
элементам выборки, а столбцы — переменным. Нумерация массива начинается с ноля
(по обеим индексам). Можно выделить три типа решаемых задач и, соответственно,
три используемых формата:

Первая задача — это задача регрессии, задача предсказания значения зависимой
переменной (нескольких переменных), если нам известны значения независимых
переменных (например, предсказание курса валюты на основе предыдущих значений).
Предсказываемая переменная при этом имеет вещественный тип. В этом случае в
первых NVars столбцах массива хранятся независимые переменные, за ними идут
столбцы с зависимыми переменными.

Вторая задача — это задача классификации, задача отнесения наблюдения к одному
из классов. Предсказываемая переменная имеет номинальное значение. Как и в
предыдущем случае, первые NVars столбцов массива содержат независимые
переменные. Следующий за ними столбец содержит номер класса (от 0 до
NClasses-1), к которому относится элемент выборки. Дробные значения округляются
до ближайшего целого.  Наконец, к третьему типу относятся задачи, которые не
являются задачами регрессии или классификации — например, кластеризация. Как
правило, обучающее множество в таких случаях содержит только независимые
переменные (первые NVars столбцов).

\subsubsection{Основные классы для работы с нейронными сетями}

Работа с нейронной сетью в AlgLib производится путем взаимодействия со
следующими классами:

\begin{itemize}
    \item multilayerperceptron — для непосредственного представления, хранения и
        использования нейронной сети;
    \item real\_2d\_array и real\_1d\_array — для хранения данных обучающей
        выборки и результатов;
    \item mlptrainer — для обучения нейронной сети;
    \item mlpreport — для хранения некоторых данных о процессе обучения
        нейронной сети.
\end{itemize}

\subsection{PyBrain}

PyBrain — это модульная библиотека для машинного обучения, написанная на языке
Python. Основной его целью является предоставление исследователю гибких, простых
в использовании, но в то же время мощных инструментов для реализации задач из
области машинного обучения, тестирования и сравнения эффективности различных
алгоритмов \cite{habra_pybrain}.

Библиотека построена по модульному принципу, что позволяет использовать её как
студентам для обучения основам, так и исследователям, нуждающимся в реализации
более сложных алгоритмов. Общая структура процедуры её использования приведена
на рисунке~\ref{img:pybrain_structure}.

\MelImg{pybrain_structure}{Структура процедуры использования PyBrain.}

Основными возможностями библиотеки являются: алгоритмы обучения с учителем, без
учителя, с подкреплением и оптимизация методом черного ящика. Также в ней есть
удобные дополнительные инструменты для работы с построеним графиков и записью и
чтением XML \cite{pybrain}.

Типичная процедура для работы с нейронной сетью в PyBrain:

\begin{itemize}
    \item Создаем нейронную сеть,
    \item Тренируем ее на обучающей выборке,
    \item Используем.
\end{itemize}

Основные классы, необходимые для создания нейронной сети и работы с ней:

\begin{itemize}
    \item ClassificationDataSet — хранилище обучающей выборки;
    \item BackpropTrainer — учитель, использующий метод обратного
        распростанения ошибки;
    \item SoftMaxLayer — выходной слой нейронной сети.
\end{itemize}

\subsection{Сравнение скорости обучения библиотек}

Каждая нейронная сеть обучалась на выборке, состоящей из 1000 прецедентов, в
каждом из которых 20 независимых параметров и один зависимый. Результат
сравнения представлен в таблице~\ref{table:speed_comparasion}.

\LTXtable{\textwidth}{tables/speed_comparasion.tex}

\section{Реализация}

Программа, использующая библиотеку AlgLib, написана на языке C++ в операционной
системе Windows, а вторая программа, использующая библиотеку PyBrain, — на
Python в операционной системе Linux. Исходные коды программ представлены в
приложениях~\ref{app:source_alglib} и \ref{app:source_pybrain}.

\MelUnnumSec{Заключение}

В результате выполнения данной работы сделан обзор основных возможностей
библиотек по работе с нейронными сетями, описан типичный алгоритм успешного
взаимодействиями с ними и реализована программа,
определяющая кредитоспособность клиента банка.

\MelLiterature{biblio}

\input{templates/latex/appendicies}
\MelAppend{Исходный код программы, использующей AlgLib}{source_alglib}

\lstset{language=C++, basicstyle=\footnotesize\ttfamily}
\lstinputlisting{sources/main.cpp}

\MelAppend{Исходный код программы, использующей PyBrain}{source_pybrain}

\lstset{language=Python}
\lstinputlisting{sources/main.py}

